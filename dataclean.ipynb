{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ff25d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values before cleaning:\n",
      "Region                    0\n",
      "Soil_Type                 0\n",
      "Crop                      0\n",
      "Rainfall_mm               0\n",
      "Temperature_Celsius       0\n",
      "Fertilizer_Used           0\n",
      "Irrigation_Used           0\n",
      "Weather_Condition         0\n",
      "Days_to_Harvest           0\n",
      "Yield_tons_per_hectare    0\n",
      "dtype: int64\n",
      "\n",
      "Crop distribution:\n",
      "Crop\n",
      "Cotton     16665\n",
      "Wheat      16664\n",
      "Soybean    16664\n",
      "Maize      16662\n",
      "Rice       16661\n",
      "Barley     16660\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced crop distribution:\n",
      "Crop\n",
      "Maize      16664\n",
      "Barley     16664\n",
      "Wheat      16664\n",
      "Rice       16664\n",
      "Soybean    16664\n",
      "Cotton     16664\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cleaned dataset saved with 99984 records\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'D:\\Internship 4 week\\Week_1\\project_week1\\crop_prediction_balanced_100k.csv')\n",
    "\n",
    "# Check for null values\n",
    "print(\"Null values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remove the row with negative yield\n",
    "df = df[df['Yield_tons_per_hectare'] >= 0]\n",
    "\n",
    "# Check for any remaining null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nCrop distribution:\")\n",
    "print(df['Crop'].value_counts())\n",
    "\n",
    "# Balance the dataset by upsampling minority classes\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['Crop'] == 'Wheat']\n",
    "df_minority1 = df[df['Crop'] == 'Rice']\n",
    "df_minority2 = df[df['Crop'] == 'Maize']\n",
    "df_minority3 = df[df['Crop'] == 'Barley']\n",
    "df_minority4 = df[df['Crop'] == 'Soybean']\n",
    "df_minority5 = df[df['Crop'] == 'Cotton']\n",
    "\n",
    "# Upsample minority classes\n",
    "df_minority1_upsampled = resample(df_minority1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority), # match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "df_minority2_upsampled = resample(df_minority2, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_minority3_upsampled = resample(df_minority3, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_minority4_upsampled = resample(df_minority4, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_minority5_upsampled = resample(df_minority5, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "# Combine majority and upsampled minority classes\n",
    "df_balanced = pd.concat([df_majority, df_minority1_upsampled, df_minority2_upsampled, \n",
    "                        df_minority3_upsampled, df_minority4_upsampled, df_minority5_upsampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check the balanced distribution\n",
    "print(\"\\nBalanced crop distribution:\")\n",
    "print(df_balanced['Crop'].value_counts())\n",
    "\n",
    "# Save the cleaned and balanced dataset\n",
    "df_balanced.to_csv('cleaned_crop_yield_dataset.csv', index=False)\n",
    "\n",
    "print(f\"\\nCleaned dataset saved with {len(df_balanced)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54fd7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: 50000 records\n",
      "\n",
      "Final crop distribution:\n",
      "Crop\n",
      "Maize      8503\n",
      "Cotton     8343\n",
      "Barley     8332\n",
      "Rice       8308\n",
      "Soybean    8288\n",
      "Wheat      8226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "50,000 record dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create an expanded dataset with 50,000 records\n",
    "def expand_dataset(df, target_size=50000):\n",
    "    # Calculate how many times we need to replicate the data\n",
    "    replication_factor = target_size // len(df) + 1\n",
    "    \n",
    "    # Replicate the dataset\n",
    "    expanded_df = pd.concat([df] * replication_factor, ignore_index=True)\n",
    "    \n",
    "    # Add some random noise to numerical columns to create variety\n",
    "    numerical_cols = ['Rainfall_mm', 'Temperature_Celsius', 'Days_to_Harvest', 'Yield_tons_per_hectare']\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        # Add small random variations (5% of standard deviation)\n",
    "        noise = np.random.normal(0, df[col].std() * 0.05, len(expanded_df))\n",
    "        expanded_df[col] = expanded_df[col] + noise\n",
    "        \n",
    "        # Ensure no negative values for these columns\n",
    "        if col in ['Rainfall_mm', 'Days_to_Harvest', 'Yield_tons_per_hectare']:\n",
    "            expanded_df[col] = expanded_df[col].clip(lower=0)\n",
    "    \n",
    "    # Trim to exact target size\n",
    "    expanded_df = expanded_df.head(target_size)\n",
    "    \n",
    "    return expanded_df\n",
    "\n",
    "# Expand the balanced dataset to 50,000 records\n",
    "expanded_df = expand_dataset(df_balanced, 50000)\n",
    "\n",
    "# Verify the final dataset\n",
    "print(f\"Final dataset size: {len(expanded_df)} records\")\n",
    "print(\"\\nFinal crop distribution:\")\n",
    "print(expanded_df['Crop'].value_counts())\n",
    "\n",
    "# Save the final dataset\n",
    "expanded_df.to_csv('crop_yield_50000.csv', index=False)\n",
    "print(\"\\n50,000 record dataset saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
